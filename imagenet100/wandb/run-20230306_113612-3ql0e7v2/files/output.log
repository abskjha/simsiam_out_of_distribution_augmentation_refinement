main_simsiam_imagenet100_ood_aug.py:157: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.
  warnings.warn('You have chosen a specific GPU. This will completely '
| distributed init (rank 0): env://
ngpus_per_node 1
Use GPU: 0 for training
=> creating model 'resnet50'
DistributedDataParallel(
  (module): SimSiam(
    (encoder): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (fc): Sequential(
        (0): Linear(in_features=2048, out_features=2048, bias=False)
        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=2048, out_features=2048, bias=False)
        (4): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=2048, out_features=2048, bias=True)
        (7): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
      )
    )
    (predictor): Sequential(
      (0): Linear(in_features=2048, out_features=512, bias=False)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Linear(in_features=512, out_features=2048, bias=True)
    )
  )
)
data_dir /scratch/leuven/346/vsc34686/datasets/Imagenet_downloads/
Length of train_dataset =  126689
data_dir /scratch/leuven/346/vsc34686/datasets/Imagenet_downloads/
data_dir /scratch/leuven/346/vsc34686/datasets/Imagenet_downloads/
Epoch: [0][    0/15837]	Time  5.351 ( 5.351)	Data  1.945 ( 1.945)	Loss 2.3274e-02 (2.3274e-02)
Epoch: [0][   10/15837]	Time  0.078 ( 0.556)	Data  0.000 ( 0.177)	Loss -1.9604e-01 (-6.4162e-02)
Epoch: [0][   20/15837]	Time  0.078 ( 0.328)	Data  0.000 ( 0.093)	Loss -5.4028e-01 (-2.1864e-01)
Epoch: [0][   30/15837]	Time  0.078 ( 0.247)	Data  0.000 ( 0.063)	Loss -7.7510e-01 (-3.6837e-01)
Epoch: [0][   40/15837]	Time  0.091 ( 0.208)	Data  0.000 ( 0.048)	Loss -8.9326e-01 (-4.8527e-01)
Epoch: [0][   50/15837]	Time  0.078 ( 0.182)	Data  0.000 ( 0.038)	Loss -9.4438e-01 (-5.7159e-01)
Epoch: [0][   60/15837]	Time  0.078 ( 0.165)	Data  0.000 ( 0.032)	Loss -9.7220e-01 (-6.3558e-01)
Epoch: [0][   70/15837]	Time  0.078 ( 0.153)	Data  0.000 ( 0.027)	Loss -9.7778e-01 (-6.8347e-01)
Epoch: [0][   80/15837]	Time  0.078 ( 0.143)	Data  0.000 ( 0.024)	Loss -9.8517e-01 (-7.2051e-01)
Epoch: [0][   90/15837]	Time  0.078 ( 0.136)	Data  0.000 ( 0.021)	Loss -9.8801e-01 (-7.4988e-01)
Epoch: [0][  100/15837]	Time  0.078 ( 0.130)	Data  0.000 ( 0.019)	Loss -9.9044e-01 (-7.7354e-01)
Epoch: [0][  110/15837]	Time  0.078 ( 0.126)	Data  0.000 ( 0.018)	Loss -9.8992e-01 (-7.9309e-01)
Epoch: [0][  120/15837]	Time  0.078 ( 0.122)	Data  0.000 ( 0.016)	Loss -9.9064e-01 (-8.0941e-01)
Epoch: [0][  130/15837]	Time  0.078 ( 0.118)	Data  0.000 ( 0.015)	Loss -9.9242e-01 (-8.2329e-01)
Epoch: [0][  140/15837]	Time  0.079 ( 0.116)	Data  0.000 ( 0.014)	Loss -9.8976e-01 (-8.3517e-01)
Epoch: [0][  150/15837]	Time  0.080 ( 0.113)	Data  0.000 ( 0.013)	Loss -9.9292e-01 (-8.4552e-01)
Epoch: [0][  160/15837]	Time  0.078 ( 0.111)	Data  0.000 ( 0.012)	Loss -9.8875e-01 (-8.5457e-01)
Epoch: [0][  170/15837]	Time  0.078 ( 0.109)	Data  0.000 ( 0.011)	Loss -9.9236e-01 (-8.6257e-01)
Epoch: [0][  180/15837]	Time  0.078 ( 0.107)	Data  0.000 ( 0.011)	Loss -9.9205e-01 (-8.6970e-01)
Epoch: [0][  190/15837]	Time  0.078 ( 0.106)	Data  0.000 ( 0.010)	Loss -9.9320e-01 (-8.7606e-01)
Epoch: [0][  200/15837]	Time  0.078 ( 0.104)	Data  0.000 ( 0.010)	Loss -9.9139e-01 (-8.8183e-01)
Epoch: [0][  210/15837]	Time  0.078 ( 0.103)	Data  0.000 ( 0.009)	Loss -9.9109e-01 (-8.8704e-01)
Epoch: [0][  220/15837]	Time  0.079 ( 0.102)	Data  0.000 ( 0.009)	Loss -9.9023e-01 (-8.9178e-01)
Epoch: [0][  230/15837]	Time  0.079 ( 0.101)	Data  0.000 ( 0.009)	Loss -9.9327e-01 (-8.9614e-01)
Epoch: [0][  240/15837]	Time  0.079 ( 0.100)	Data  0.000 ( 0.008)	Loss -9.9096e-01 (-9.0013e-01)
Epoch: [0][  250/15837]	Time  0.077 ( 0.099)	Data  0.000 ( 0.008)	Loss -9.9139e-01 (-9.0379e-01)
Epoch: [0][  260/15837]	Time  0.078 ( 0.098)	Data  0.000 ( 0.008)	Loss -9.9062e-01 (-9.0716e-01)
Epoch: [0][  270/15837]	Time  0.078 ( 0.098)	Data  0.000 ( 0.007)	Loss -9.9421e-01 (-9.1030e-01)
Epoch: [0][  280/15837]	Time  0.078 ( 0.097)	Data  0.000 ( 0.007)	Loss -9.9379e-01 (-9.1324e-01)
Epoch: [0][  290/15837]	Time  0.078 ( 0.096)	Data  0.000 ( 0.007)	Loss -9.9348e-01 (-9.1599e-01)
Epoch: [0][  300/15837]	Time  0.078 ( 0.096)	Data  0.000 ( 0.007)	Loss -9.9290e-01 (-9.1852e-01)
Epoch: [0][  310/15837]	Time  0.078 ( 0.095)	Data  0.000 ( 0.006)	Loss -9.9186e-01 (-9.2088e-01)
Epoch: [0][  320/15837]	Time  0.078 ( 0.095)	Data  0.000 ( 0.006)	Loss -9.9328e-01 (-9.2313e-01)
Epoch: [0][  330/15837]	Time  0.078 ( 0.094)	Data  0.000 ( 0.006)	Loss -9.9321e-01 (-9.2525e-01)
Epoch: [0][  340/15837]	Time  0.078 ( 0.094)	Data  0.000 ( 0.006)	Loss -9.9123e-01 (-9.2724e-01)
Epoch: [0][  350/15837]	Time  0.078 ( 0.093)	Data  0.000 ( 0.006)	Loss -9.9335e-01 (-9.2914e-01)
Epoch: [0][  360/15837]	Time  0.078 ( 0.093)	Data  0.000 ( 0.005)	Loss -9.9369e-01 (-9.3093e-01)
Epoch: [0][  370/15837]	Time  0.078 ( 0.092)	Data  0.000 ( 0.005)	Loss -9.9355e-01 (-9.3261e-01)
Epoch: [0][  380/15837]	Time  0.078 ( 0.092)	Data  0.000 ( 0.005)	Loss -9.9417e-01 (-9.3421e-01)
Epoch: [0][  390/15837]	Time  0.078 ( 0.092)	Data  0.000 ( 0.005)	Loss -9.9334e-01 (-9.3573e-01)
Epoch: [0][  400/15837]	Time  0.078 ( 0.091)	Data  0.000 ( 0.005)	Loss -9.9247e-01 (-9.3716e-01)
Epoch: [0][  410/15837]	Time  0.078 ( 0.091)	Data  0.000 ( 0.005)	Loss -9.9433e-01 (-9.3854e-01)
Epoch: [0][  420/15837]	Time  0.078 ( 0.091)	Data  0.000 ( 0.005)	Loss -9.9354e-01 (-9.3985e-01)
Epoch: [0][  430/15837]	Time  0.078 ( 0.090)	Data  0.000 ( 0.005)	Loss -9.9390e-01 (-9.4110e-01)
Epoch: [0][  440/15837]	Time  0.079 ( 0.090)	Data  0.000 ( 0.005)	Loss -9.9351e-01 (-9.4230e-01)
Epoch: [0][  450/15837]	Time  0.078 ( 0.090)	Data  0.000 ( 0.004)	Loss -9.9269e-01 (-9.4344e-01)
Epoch: [0][  460/15837]	Time  0.078 ( 0.090)	Data  0.000 ( 0.004)	Loss -9.9395e-01 (-9.4454e-01)
Epoch: [0][  470/15837]	Time  0.078 ( 0.089)	Data  0.000 ( 0.004)	Loss -9.9490e-01 (-9.4560e-01)
Epoch: [0][  480/15837]	Time  0.078 ( 0.089)	Data  0.000 ( 0.004)	Loss -9.9383e-01 (-9.4661e-01)
Epoch: [0][  490/15837]	Time  0.078 ( 0.089)	Data  0.000 ( 0.004)	Loss -9.9458e-01 (-9.4759e-01)
Epoch: [0][  500/15837]	Time  0.078 ( 0.089)	Data  0.000 ( 0.004)	Loss -9.9506e-01 (-9.4853e-01)
Epoch: [0][  510/15837]	Time  0.078 ( 0.089)	Data  0.000 ( 0.004)	Loss -9.9455e-01 (-9.4942e-01)
Epoch: [0][  520/15837]	Time  0.079 ( 0.088)	Data  0.000 ( 0.004)	Loss -9.9498e-01 (-9.5029e-01)
Epoch: [0][  530/15837]	Time  0.078 ( 0.088)	Data  0.000 ( 0.004)	Loss -9.9500e-01 (-9.5112e-01)
Epoch: [0][  540/15837]	Time  0.078 ( 0.088)	Data  0.000 ( 0.004)	Loss -9.9468e-01 (-9.5193e-01)
Epoch: [0][  550/15837]	Time  0.078 ( 0.088)	Data  0.000 ( 0.004)	Loss -9.9475e-01 (-9.5271e-01)
Epoch: [0][  560/15837]	Time  0.075 ( 0.088)	Data  0.000 ( 0.004)	Loss -9.9357e-01 (-9.5346e-01)
Epoch: [0][  570/15837]	Time  0.079 ( 0.087)	Data  0.000 ( 0.004)	Loss -9.9454e-01 (-9.5418e-01)
Epoch: [0][  580/15837]	Time  0.078 ( 0.087)	Data  0.000 ( 0.003)	Loss -9.9484e-01 (-9.5488e-01)
Epoch: [0][  590/15837]	Time  0.078 ( 0.087)	Data  0.000 ( 0.003)	Loss -9.9562e-01 (-9.5556e-01)
Epoch: [0][  600/15837]	Time  0.078 ( 0.087)	Data  0.000 ( 0.003)	Loss -9.9413e-01 (-9.5621e-01)
Epoch: [0][  610/15837]	Time  0.076 ( 0.087)	Data  0.001 ( 0.003)	Loss -9.9356e-01 (-9.5684e-01)
Epoch: [0][  620/15837]	Time  0.079 ( 0.087)	Data  0.000 ( 0.003)	Loss -9.9422e-01 (-9.5746e-01)
Epoch: [0][  630/15837]	Time  0.079 ( 0.087)	Data  0.000 ( 0.003)	Loss -9.9499e-01 (-9.5805e-01)
Epoch: [0][  640/15837]	Time  0.078 ( 0.086)	Data  0.000 ( 0.003)	Loss -9.9529e-01 (-9.5863e-01)
Epoch: [0][  650/15837]	Time  0.078 ( 0.086)	Data  0.000 ( 0.003)	Loss -9.9528e-01 (-9.5919e-01)
Epoch: [0][  660/15837]	Time  0.078 ( 0.086)	Data  0.000 ( 0.003)	Loss -9.9566e-01 (-9.5973e-01)
Epoch: [0][  670/15837]	Time  0.078 ( 0.086)	Data  0.000 ( 0.003)	Loss -9.9555e-01 (-9.6026e-01)
Epoch: [0][  680/15837]	Time  0.078 ( 0.086)	Data  0.000 ( 0.003)	Loss -9.9566e-01 (-9.6078e-01)
Epoch: [0][  690/15837]	Time  0.079 ( 0.086)	Data  0.000 ( 0.003)	Loss -9.9553e-01 (-9.6128e-01)
Epoch: [0][  700/15837]	Time  0.079 ( 0.086)	Data  0.000 ( 0.003)	Loss -9.9589e-01 (-9.6177e-01)
Epoch: [0][  710/15837]	Time  0.078 ( 0.086)	Data  0.000 ( 0.003)	Loss -9.9580e-01 (-9.6224e-01)
Epoch: [0][  720/15837]	Time  0.078 ( 0.086)	Data  0.000 ( 0.003)	Loss -9.9534e-01 (-9.6270e-01)
Epoch: [0][  730/15837]	Time  0.078 ( 0.085)	Data  0.000 ( 0.003)	Loss -9.9571e-01 (-9.6315e-01)
Epoch: [0][  740/15837]	Time  0.078 ( 0.085)	Data  0.000 ( 0.003)	Loss -9.9581e-01 (-9.6359e-01)
Epoch: [0][  750/15837]	Time  0.078 ( 0.085)	Data  0.000 ( 0.003)	Loss -9.9602e-01 (-9.6402e-01)
Epoch: [0][  760/15837]	Time  0.078 ( 0.085)	Data  0.000 ( 0.003)	Loss -9.9557e-01 (-9.6444e-01)
Epoch: [0][  770/15837]	Time  0.078 ( 0.085)	Data  0.000 ( 0.003)	Loss -9.9568e-01 (-9.6484e-01)
Epoch: [0][  780/15837]	Time  0.078 ( 0.085)	Data  0.000 ( 0.003)	Loss -9.9609e-01 (-9.6524e-01)
Epoch: [0][  790/15837]	Time  0.079 ( 0.085)	Data  0.000 ( 0.003)	Loss -9.9564e-01 (-9.6562e-01)
Epoch: [0][  800/15837]	Time  0.079 ( 0.085)	Data  0.000 ( 0.003)	Loss -9.9574e-01 (-9.6600e-01)
Epoch: [0][  810/15837]	Time  0.079 ( 0.085)	Data  0.000 ( 0.003)	Loss -9.9529e-01 (-9.6637e-01)
Epoch: [0][  820/15837]	Time  0.079 ( 0.085)	Data  0.000 ( 0.002)	Loss -9.9495e-01 (-9.6672e-01)
Epoch: [0][  830/15837]	Time  0.080 ( 0.085)	Data  0.000 ( 0.002)	Loss -9.9528e-01 (-9.6706e-01)
Epoch: [0][  840/15837]	Time  0.082 ( 0.085)	Data  0.000 ( 0.002)	Loss -9.9461e-01 (-9.6739e-01)
Epoch: [0][  850/15837]	Time  0.080 ( 0.084)	Data  0.000 ( 0.002)	Loss -9.9485e-01 (-9.6771e-01)
Epoch: [0][  860/15837]	Time  0.079 ( 0.084)	Data  0.000 ( 0.002)	Loss -9.9551e-01 (-9.6803e-01)
Epoch: [0][  870/15837]	Time  0.079 ( 0.084)	Data  0.000 ( 0.002)	Loss -9.9513e-01 (-9.6834e-01)
Epoch: [0][  880/15837]	Time  0.079 ( 0.084)	Data  0.000 ( 0.002)	Loss -9.9523e-01 (-9.6864e-01)
Epoch: [0][  890/15837]	Time  0.079 ( 0.084)	Data  0.000 ( 0.002)	Loss -9.9526e-01 (-9.6894e-01)
Epoch: [0][  900/15837]	Time  0.078 ( 0.084)	Data  0.000 ( 0.002)	Loss -9.9526e-01 (-9.6923e-01)
Epoch: [0][  910/15837]	Time  0.078 ( 0.084)	Data  0.000 ( 0.002)	Loss -9.9537e-01 (-9.6951e-01)
Epoch: [0][  920/15837]	Time  0.078 ( 0.084)	Data  0.000 ( 0.002)	Loss -9.9547e-01 (-9.6979e-01)
Epoch: [0][  930/15837]	Time  0.078 ( 0.084)	Data  0.000 ( 0.002)	Loss -9.9486e-01 (-9.7007e-01)
Epoch: [0][  940/15837]	Time  0.080 ( 0.084)	Data  0.000 ( 0.002)	Loss -9.9489e-01 (-9.7033e-01)
Epoch: [0][  950/15837]	Time  0.077 ( 0.084)	Data  0.000 ( 0.002)	Loss -9.9477e-01 (-9.7059e-01)
Epoch: [0][  960/15837]	Time  0.080 ( 0.084)	Data  0.000 ( 0.002)	Loss -9.9550e-01 (-9.7085e-01)
Epoch: [0][  970/15837]	Time  0.079 ( 0.084)	Data  0.000 ( 0.002)	Loss -9.9599e-01 (-9.7110e-01)
Epoch: [0][  980/15837]	Time  0.080 ( 0.084)	Data  0.000 ( 0.002)	Loss -9.9533e-01 (-9.7135e-01)
Epoch: [0][  990/15837]	Time  0.080 ( 0.084)	Data  0.000 ( 0.002)	Loss -9.9590e-01 (-9.7159e-01)
Epoch: [0][ 1000/15837]	Time  0.080 ( 0.084)	Data  0.000 ( 0.002)	Loss -9.9529e-01 (-9.7183e-01)
Epoch: [0][ 1010/15837]	Time  0.078 ( 0.084)	Data  0.000 ( 0.002)	Loss -9.9505e-01 (-9.7206e-01)
Epoch: [0][ 1020/15837]	Time  0.078 ( 0.084)	Data  0.000 ( 0.002)	Loss -9.9579e-01 (-9.7229e-01)
Epoch: [0][ 1030/15837]	Time  0.078 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9560e-01 (-9.7251e-01)
Epoch: [0][ 1040/15837]	Time  0.078 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9562e-01 (-9.7274e-01)
Epoch: [0][ 1050/15837]	Time  0.079 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9547e-01 (-9.7295e-01)
Epoch: [0][ 1060/15837]	Time  0.078 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9562e-01 (-9.7317e-01)
Epoch: [0][ 1070/15837]	Time  0.078 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9427e-01 (-9.7338e-01)
Epoch: [0][ 1080/15837]	Time  0.080 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9622e-01 (-9.7358e-01)
Epoch: [0][ 1090/15837]	Time  0.078 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9553e-01 (-9.7378e-01)
Epoch: [0][ 1100/15837]	Time  0.078 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9595e-01 (-9.7398e-01)
Epoch: [0][ 1110/15837]	Time  0.078 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9563e-01 (-9.7417e-01)
Epoch: [0][ 1120/15837]	Time  0.078 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9576e-01 (-9.7437e-01)
Epoch: [0][ 1130/15837]	Time  0.079 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9585e-01 (-9.7455e-01)
Epoch: [0][ 1140/15837]	Time  0.078 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9567e-01 (-9.7474e-01)
Epoch: [0][ 1150/15837]	Time  0.083 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9449e-01 (-9.7492e-01)
Epoch: [0][ 1160/15837]	Time  0.078 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9549e-01 (-9.7509e-01)
Epoch: [0][ 1170/15837]	Time  0.080 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9584e-01 (-9.7527e-01)
Epoch: [0][ 1180/15837]	Time  0.079 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9550e-01 (-9.7544e-01)
Epoch: [0][ 1190/15837]	Time  0.081 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9514e-01 (-9.7560e-01)
Epoch: [0][ 1200/15837]	Time  0.079 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9565e-01 (-9.7577e-01)
Epoch: [0][ 1210/15837]	Time  0.081 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9476e-01 (-9.7593e-01)
Epoch: [0][ 1220/15837]	Time  0.080 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9479e-01 (-9.7609e-01)
Epoch: [0][ 1230/15837]	Time  0.081 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9587e-01 (-9.7624e-01)
Epoch: [0][ 1240/15837]	Time  0.077 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9507e-01 (-9.7640e-01)
Epoch: [0][ 1250/15837]	Time  0.078 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9604e-01 (-9.7655e-01)
Epoch: [0][ 1260/15837]	Time  0.078 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9529e-01 (-9.7670e-01)
Epoch: [0][ 1270/15837]	Time  0.079 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9476e-01 (-9.7685e-01)
Epoch: [0][ 1280/15837]	Time  0.080 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9522e-01 (-9.7700e-01)
Epoch: [0][ 1290/15837]	Time  0.079 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9584e-01 (-9.7714e-01)
Epoch: [0][ 1300/15837]	Time  0.079 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9578e-01 (-9.7729e-01)
Epoch: [0][ 1310/15837]	Time  0.079 ( 0.083)	Data  0.000 ( 0.002)	Loss -9.9565e-01 (-9.7743e-01)
Epoch: [0][ 1320/15837]	Time  0.079 ( 0.082)	Data  0.000 ( 0.002)	Loss -9.9587e-01 (-9.7757e-01)
Epoch: [0][ 1330/15837]	Time  0.079 ( 0.082)	Data  0.000 ( 0.002)	Loss -9.9599e-01 (-9.7770e-01)
Epoch: [0][ 1340/15837]	Time  0.079 ( 0.082)	Data  0.000 ( 0.002)	Loss -9.9573e-01 (-9.7784e-01)
Epoch: [0][ 1350/15837]	Time  0.079 ( 0.082)	Data  0.000 ( 0.002)	Loss -9.9600e-01 (-9.7797e-01)
Epoch: [0][ 1360/15837]	Time  0.079 ( 0.082)	Data  0.000 ( 0.002)	Loss -9.9507e-01 (-9.7810e-01)
Epoch: [0][ 1370/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.002)	Loss -9.9578e-01 (-9.7823e-01)
Epoch: [0][ 1380/15837]	Time  0.079 ( 0.082)	Data  0.000 ( 0.002)	Loss -9.9536e-01 (-9.7835e-01)
Epoch: [0][ 1390/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.002)	Loss -9.9624e-01 (-9.7848e-01)
Epoch: [0][ 1400/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9633e-01 (-9.7860e-01)
Epoch: [0][ 1410/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9529e-01 (-9.7873e-01)
Epoch: [0][ 1420/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9502e-01 (-9.7885e-01)
Epoch: [0][ 1430/15837]	Time  0.079 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9612e-01 (-9.7896e-01)
Epoch: [0][ 1440/15837]	Time  0.079 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9627e-01 (-9.7908e-01)
Epoch: [0][ 1450/15837]	Time  0.077 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9620e-01 (-9.7920e-01)
Epoch: [0][ 1460/15837]	Time  0.079 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9552e-01 (-9.7931e-01)
Epoch: [0][ 1470/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9628e-01 (-9.7942e-01)
Epoch: [0][ 1480/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9607e-01 (-9.7953e-01)
Epoch: [0][ 1490/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9607e-01 (-9.7964e-01)
Epoch: [0][ 1500/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9571e-01 (-9.7975e-01)
Epoch: [0][ 1510/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9631e-01 (-9.7986e-01)
Epoch: [0][ 1520/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9613e-01 (-9.7996e-01)
Epoch: [0][ 1530/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9600e-01 (-9.8007e-01)
Epoch: [0][ 1540/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9573e-01 (-9.8017e-01)
Epoch: [0][ 1550/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9557e-01 (-9.8027e-01)
Epoch: [0][ 1560/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9552e-01 (-9.8037e-01)
Epoch: [0][ 1570/15837]	Time  0.079 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9582e-01 (-9.8047e-01)
Epoch: [0][ 1580/15837]	Time  0.080 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9626e-01 (-9.8057e-01)
Epoch: [0][ 1590/15837]	Time  0.079 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9618e-01 (-9.8066e-01)
Epoch: [0][ 1600/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9543e-01 (-9.8076e-01)
Epoch: [0][ 1610/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9608e-01 (-9.8085e-01)
Epoch: [0][ 1620/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9589e-01 (-9.8095e-01)
Epoch: [0][ 1630/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9693e-01 (-9.8105e-01)
Epoch: [0][ 1640/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9625e-01 (-9.8114e-01)
Epoch: [0][ 1650/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9623e-01 (-9.8123e-01)
Epoch: [0][ 1660/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9674e-01 (-9.8133e-01)
Epoch: [0][ 1670/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9672e-01 (-9.8142e-01)
Epoch: [0][ 1680/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9666e-01 (-9.8151e-01)
Epoch: [0][ 1690/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9684e-01 (-9.8160e-01)
Epoch: [0][ 1700/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9653e-01 (-9.8168e-01)
Epoch: [0][ 1710/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9675e-01 (-9.8177e-01)
Epoch: [0][ 1720/15837]	Time  0.079 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9688e-01 (-9.8186e-01)
Epoch: [0][ 1730/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9703e-01 (-9.8194e-01)
Epoch: [0][ 1740/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9680e-01 (-9.8203e-01)
Epoch: [0][ 1750/15837]	Time  0.078 ( 0.082)	Data  0.000 ( 0.001)	Loss -9.9658e-01 (-9.8211e-01)
Epoch: [0][ 1760/15837]	Time  0.078 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9664e-01 (-9.8219e-01)
Epoch: [0][ 1770/15837]	Time  0.078 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9658e-01 (-9.8228e-01)
Epoch: [0][ 1780/15837]	Time  0.079 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9640e-01 (-9.8236e-01)
Epoch: [0][ 1790/15837]	Time  0.078 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9653e-01 (-9.8243e-01)
Epoch: [0][ 1800/15837]	Time  0.078 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9657e-01 (-9.8251e-01)
Epoch: [0][ 1810/15837]	Time  0.079 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9601e-01 (-9.8259e-01)
Epoch: [0][ 1820/15837]	Time  0.078 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9645e-01 (-9.8267e-01)
Epoch: [0][ 1830/15837]	Time  0.078 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9654e-01 (-9.8274e-01)
Epoch: [0][ 1840/15837]	Time  0.078 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9665e-01 (-9.8282e-01)
Epoch: [0][ 1850/15837]	Time  0.078 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9647e-01 (-9.8289e-01)
Epoch: [0][ 1860/15837]	Time  0.078 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9624e-01 (-9.8296e-01)
Epoch: [0][ 1870/15837]	Time  0.078 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9666e-01 (-9.8304e-01)
Epoch: [0][ 1880/15837]	Time  0.078 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9663e-01 (-9.8311e-01)
Epoch: [0][ 1890/15837]	Time  0.078 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9674e-01 (-9.8318e-01)
Epoch: [0][ 1900/15837]	Time  0.078 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9685e-01 (-9.8325e-01)
Epoch: [0][ 1910/15837]	Time  0.079 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9653e-01 (-9.8332e-01)
Epoch: [0][ 1920/15837]	Time  0.078 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9662e-01 (-9.8339e-01)
Epoch: [0][ 1930/15837]	Time  0.078 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9650e-01 (-9.8346e-01)
Epoch: [0][ 1940/15837]	Time  0.078 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9644e-01 (-9.8353e-01)
Epoch: [0][ 1950/15837]	Time  0.078 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9677e-01 (-9.8360e-01)
Epoch: [0][ 1960/15837]	Time  0.077 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9714e-01 (-9.8366e-01)
Epoch: [0][ 1970/15837]	Time  0.078 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9675e-01 (-9.8373e-01)
Epoch: [0][ 1980/15837]	Time  0.078 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9679e-01 (-9.8379e-01)
Epoch: [0][ 1990/15837]	Time  0.078 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9675e-01 (-9.8386e-01)
Traceback (most recent call last):
  File "main_simsiam_imagenet100_ood_aug.py", line 668, in <module>
    main()
  File "main_simsiam_imagenet100_ood_aug.py", line 168, in main
    main_worker(args.gpu, ngpus_per_node, args)
  File "main_simsiam_imagenet100_ood_aug.py", line 355, in main_worker
    ood_train(memory_loader, c_model, r_model, c_model_optimizer, epoch, args)
  File "main_simsiam_imagenet100_ood_aug.py", line 648, in ood_train
    losses.update(loss.item(), images.size(0))
KeyboardInterrupt
Epoch: [0][ 2000/15837]	Time  0.078 ( 0.081)	Data  0.000 ( 0.001)	Loss -9.9675e-01 (-9.8392e-01)